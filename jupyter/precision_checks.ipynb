{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a248a34-9b14-4b36-b856-1c9290aa3e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95bfa71-c3bd-41c5-bd01-549f580bc16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from movie_pkg.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14356a4-572d-4d4c-a82e-b0feac63e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'llm_checks' # change to fit however you have the data saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b5ee20e-e8d0-4a83-87df-97332aab6976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      subject  alignment\n",
      "0   temple056   0.722222\n",
      "1   temple057   1.000000\n",
      "2   temple058   0.856785\n",
      "3   temple059   0.952072\n",
      "4   temple060   0.928734\n",
      "..        ...        ...\n",
      "61  temple130   1.000000\n",
      "62  temple131   1.000000\n",
      "63  temple132   1.000000\n",
      "64  temple135   1.000000\n",
      "65  temple136   0.991803\n",
      "\n",
      "[66 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "SIM_THRESHOLD = 0.90  # we're using a similarity threshold because human coding can result in differences in spacing, \n",
    "#    capitalization, etc. which are not meaningful differences. We just care if the same utterance was mapped to the same ground-truth\n",
    "#    hence the 90% similarity threshold\n",
    "\n",
    "alignments = []\n",
    "\n",
    "for subject in get_scan_subs():\n",
    "    subject_scores = []\n",
    "    # not all subjects watched both movies, so we have a utility to figure out which one's did and didn't\n",
    "    for movie in get_subject_movies(subject):\n",
    "        file1 = f\"{base}/checked/subj-{subject}_{movie}_event_coded.tsv\"\n",
    "        file2 = f\"{base}/scan_event_coding_final/{subject}/subj-{subject}_{movie}_event_coded.tsv\"\n",
    "\n",
    "        df1 = pd.read_csv(file1, sep=\"\\t\")\n",
    "        df2 = pd.read_csv(file2, sep=\"\\t\")\n",
    "\n",
    "        # match file length for comparison\n",
    "        n = min(len(df1), len(df2))\n",
    "        col1 = df1.loc[:n-1, 'detail_recall'].astype(str).fillna('').str.strip()\n",
    "        col2 = df2.loc[:n-1, 'detail_recall'].astype(str).fillna('').str.strip()\n",
    "\n",
    "        matches = []\n",
    "        for a, b in zip(col1, col2):\n",
    "            # remove punctuation and lowercase for comparison\n",
    "            a_clean = re.sub(r'\\W+', '', a.lower())\n",
    "            b_clean = re.sub(r'\\W+', '', b.lower())\n",
    "\n",
    "            # match if both blank (no mapped event) OR sufficiently similar (same mapped event)\n",
    "            if a_clean == '' and b_clean == '':\n",
    "                matches.append(1)\n",
    "            else:\n",
    "                ratio = SequenceMatcher(None, a_clean, b_clean).ratio()\n",
    "                matches.append(1 if ratio >= SIM_THRESHOLD else 0)\n",
    "\n",
    "        subject_scores.append(float(np.mean(matches)) if matches else np.nan)\n",
    "\n",
    "    alignments.append(np.nanmean(subject_scores) if subject_scores else np.nan)\n",
    "\n",
    "alignments_df = pd.DataFrame({'subject': get_scan_subs(), 'alignment': alignments})\n",
    "print(alignments_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39afd9bc-6aca-48e1-8c1c-6b29018291be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.942019236076613"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(alignments_df['alignment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af44ea-175d-416d-9116-0aee3049ba87",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Human adjustments were minimal, with only 5.8% of codes requiring revision and 94.2% confirmed without change."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
