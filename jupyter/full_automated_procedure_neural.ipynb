{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3c90d25-52c9-4878-99fa-4664b6815865",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from argparse import ArgumentParser\n",
    "import os.path as osp\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d147504c-101d-4dd7-9eb5-82f3baedf89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from movie_pkg.scan_utils import *\n",
    "from movie_pkg.open_ai_prompts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159c7f84-b710-43d7-9353-eaa1405c8211",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a52bd1b6-fdd0-4bcb-b0b2-82b252fb12e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"llm_coding\" # udpate however necessary\n",
    "model = \"gpt-4.1\" # this was the most recent model available via API call when this project was done, but this can likely be updated for future work\n",
    "# client = OpenAI(\n",
    "#     api_key=\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a345f972-1d79-4a31-bafd-abed74312e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = get_scan_subs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd7b874-ead5-4f6a-af09-0990d1749ad9",
   "metadata": {},
   "source": [
    "### Parsing:\n",
    "* First, parse the free recall text into individual utterances (typically one agent-action pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf857c4-6404-4baa-a91e-8ecbbdbf1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"\" # adjust as necessary\n",
    "\n",
    "subs = subjects\n",
    "\n",
    "for subject in subs:\n",
    "    print(f\"running for subject {subject}\")\n",
    "    movie_list = []\n",
    "    out_dir = f\"{base}/llm_coding/scan_parsing/{subject}\"\n",
    "    os.makedirs(out_dir, exist_ok = True)\n",
    "    for movie in get_subject_movies(subject):\n",
    "        print(f\"     parsing movie {movie}...\")\n",
    "        \n",
    "        example_data = pd.read_csv(f\"{base}/movie_pkg/training/parse_examples/{movie}_example.csv\")\n",
    "        # provide the model example input data\n",
    "        example_txt = \" \".join(example_data['transcript'])\n",
    "        # provide the model an example of the desired output\n",
    "        example_out = example_data['transcript']\n",
    "        # provide the subject's recall as a string\n",
    "        recall_txt = clean_recall_txt(load_recall_txt(subject, movie))\n",
    "\n",
    "        # return and save out a list of parsed events and any removed utterances\n",
    "        result = call_openai_parse(\n",
    "            client, model, example_txt, example_out, recall_txt\n",
    "        )\n",
    "\n",
    "        pd.DataFrame({'utterance': result}).to_csv(\n",
    "            f\"{out_dir}/subj-{subject}_{movie}_parsed.tsv\", sep='\\t', index=False\n",
    "        )\n",
    "\n",
    "        # append output to list for parsing report\n",
    "        movie_list.append({\"movie\": movie,\n",
    "        \"recall_segments\": result,\n",
    "        \"original_recall_text\": recall_txt,\n",
    "        })\n",
    "    # generate a parsing report to review identified and removed events\n",
    "    generate_parsing_report(movie_list, f\"{base}/scan_reports/parsing/{subject}_parsing_report.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35125638-b2ef-4d14-bd17-c605d3c75d5a",
   "metadata": {},
   "source": [
    "### Event coding:\n",
    "* Use human generated training data and engineered prompts to align parsed events to reference transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f8a008-c5ce-45cc-ac9f-f03ccedf13c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report_only = False\n",
    "\n",
    "base = \"\" # adjust as necessary\n",
    "\n",
    "for subject in subjects:\n",
    "    print(f\"running for subject {subject}\")\n",
    "    movie_list = []\n",
    "    out_dir = f\"{base}/llm_coding/scan_event_coding_final/{subject}\"\n",
    "    os.makedirs(out_dir, exist_ok = True)\n",
    "    for movie in get_subject_movies(subject):\n",
    "\n",
    "        print(f\"     running event coding for {movie}...\")\n",
    "        blank_recall_json = get_blank_recall_json(movie)\n",
    " \n",
    "        examples = pull_training_event_coding(movie)\n",
    "\n",
    "        recall_json = json.loads(recall_tsv_to_json(subject, movie, list_column=\"utterance\"))\n",
    "\n",
    "        if not report_only:\n",
    "            # return and save out a list of coded events\n",
    "            result = call_openai_event_coding_PRESERVE(\n",
    "                client, model, blank_recall_json, examples, recall_json\n",
    "            )\n",
    "            with open(\n",
    "                f\"{out_dir}/subj-{subject}_{movie}_event_coded.json\",\n",
    "                \"w\",\n",
    "            ) as f:\n",
    "                json.dump(result, f, indent=4)\n",
    "            pass\n",
    "            tsv_path = f\"{out_dir}/subj-{subject}_{movie}_event_coded.tsv\"\n",
    "            json_to_csv(result, tsv_path, subject)\n",
    "        else:\n",
    "            tsv_path = f\"{out_dir}/subj-{subject}_{movie}_event_coded.tsv\"\n",
    "            results = pd.read_csv(tsv_path, delimiter = '\\t')\n",
    "        \n",
    "        recall_list = [entry[\"transcript\"] for entry in recall_json] \n",
    "        movie_list.append({\n",
    "                \"movie\": movie,\n",
    "                \"coded_csv_path\": tsv_path,\n",
    "                \"recall_list\": recall_list\n",
    "            })\n",
    "    generate_coding_report(movie_list, f\"{base}/coding_reports/scan/{subject}_coding_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ea619-22f1-43b7-a825-bd212ae38d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8ab49a-c9c6-4f07-a726-8c9d856fbc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72beab25-98f1-47ee-afb4-f3da46cde11c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e0eb8-074d-4e7b-82fb-5c9d46af8ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
